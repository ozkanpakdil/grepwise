name: Performance Benchmarks

on:
  workflow_dispatch:
  push:
    branches: [ main ]
    paths-ignore:
      - 'docs/perf/**'
  release:
    types: [ published ]

jobs:
  perf:
    name: Run JMeter performance tests
    runs-on: ubuntu-latest
    permissions:
      contents: write
      actions: read
      id-token: write
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Java
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: '24'
          cache: 'maven'

      - name: Setup Node (for frontend build during Maven)
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Build application (skip unit tests)
        run: mvn -B -DskipTests package

      - name: Launch GrepWise
        run: |
          nohup java -jar target/grepwise-0.0.1-SNAPSHOT.jar > app.log 2>&1 &
          echo $! > app.pid
          echo "Waiting for application health..."
          for i in {1..90}; do
            if curl -fsS http://localhost:8080/actuator/health | grep -q '"status":"UP"'; then
              echo "Application is healthy."; break; fi
            sleep 2
          done

      - name: Run JMeter performance tests
        env:
          GW_HOST: localhost
          GW_HTTP_PORT: '8080'
          GW_SYSLOG_PORT: '1514'
          USERS: '10'
          DURATION: '60'
        run: |
          mvn -B -Pperf-test \
            -Dgw.host=${GW_HOST} \
            -Dgw.http.port=${GW_HTTP_PORT} \
            -Dgw.syslog.port=${GW_SYSLOG_PORT} \
            -Dusers=${USERS} \
            -DdurationSeconds=${DURATION} verify

      - name: Build perf summary and compare to history
        id: summarize
        if: always()
        run: |
          python3 scripts/perf/summarize_and_compare.py || true
          echo "code=$?" >> $GITHUB_OUTPUT
          if [ -f target/jmeter/perf-summary.md ]; then
            cat target/jmeter/perf-summary.md >> $GITHUB_STEP_SUMMARY
          else
            echo "## Performance Test Summary" >> $GITHUB_STEP_SUMMARY
          fi
          echo "\n### Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "- HTML dashboards: target/jmeter/reports/…" >> $GITHUB_STEP_SUMMARY
          echo "- Raw CSV results: target/jmeter/results/…" >> $GITHUB_STEP_SUMMARY

      - name: Commit perf history & badge
        if: ${{ always() && github.ref == 'refs/heads/main' }}
        run: |
          git config user.name "github-actions"
          git config user.email "github-actions@github.com"
          git add docs/perf/history.csv docs/perf/badge.svg || true
          git commit -m "chore(perf): update perf history [skip ci]" || echo "No history changes"
          git push || true

      - name: Enforce block threshold (>20% regression)
        if: ${{ steps.summarize.outputs.code == '2' }}
        run: |
          echo "Performance regression exceeds 20% in p95 latency for at least one scenario. Failing the job." >&2
          exit 1

      - name: Upload artifacts (JMeter reports & logs)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: perf-results-${{ github.run_number }}
          path: |
            target/jmeter/**
            docs/perf/history.csv
            docs/perf/badge.svg
            app.log
            app.pid

      - name: Cleanup (stop app)
        if: always()
        run: |
          if [ -f app.pid ]; then
            kill $(cat app.pid) || true
          fi
